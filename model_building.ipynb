{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Created on Sun Apr 12 10:30:10 2020\n",
    "\n",
    "@author: Ken\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "\n",
    "df = pd.read_csv('eda_data.csv')\n",
    "\n",
    "# choose relevant columns \n",
    "df.columns\n",
    "\n",
    "df_model = df[['avg_salary','Rating','Size','Type of ownership','Industry','Sector','Revenue','num_comp','hourly','employer_provided',\n",
    "             'job_state','same_state','age','python_yn','spark','aws','excel','job_simp','seniority','desc_len']]\n",
    "\n",
    "# get dummy data \n",
    "df_dum = pd.get_dummies(df_model)\n",
    "\n",
    "# train test split \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_dum.drop('avg_salary', axis =1)\n",
    "y = df_dum.avg_salary.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# multiple linear regression \n",
    "import statsmodels.api as sm\n",
    "# sm.add_constant in statsmodel is the same as sklearn's fit_intercept parameter \n",
    "# in LinearRegression(). If you don't do sm.add_constant or when LinearRegression(fit_intercept=False), \n",
    "# then both statsmodels and sklearn algorithms assume that b=0 in y = mx + b, \n",
    "# and it'll fit the model using b=0 instead of calculating what b is supposed to be based on your data.\n",
    "X_sm = X = sm.add_constant(X)\n",
    "model = sm.OLS(y,X_sm)\n",
    "model.fit().summary()\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "#neg_mean_absolute_error给的是负绝对值ssr，在多算法选优的时候，方便排序，ssr=10肯定好于ssr=20，但是如果是正数，排序回认为20分高于10\n",
    "np.mean(cross_val_score(lm,X_train,y_train, scoring = 'neg_mean_absolute_error', cv= 3))\n",
    "\n",
    "# lasso regression \n",
    "# 降低模型对训练数据集的敏感度，一定程度上优化了模型\n",
    "lm_l = Lasso(alpha=.13)\n",
    "lm_l.fit(X_train,y_train)\n",
    "np.mean(cross_val_score(lm_l,X_train,y_train, scoring = 'neg_mean_absolute_error', cv= 3))\n",
    "\n",
    "alpha = []\n",
    "error = []\n",
    "\n",
    "for i in range(1,100):\n",
    "    alpha.append(i/100)\n",
    "    lml = Lasso(alpha=(i/100))\n",
    "    error.append(np.mean(cross_val_score(lml,X_train,y_train, scoring = 'neg_mean_absolute_error', cv= 3)))\n",
    "    \n",
    "plt.plot(alpha,error)\n",
    "\n",
    "err = tuple(zip(alpha,error))\n",
    "df_err = pd.DataFrame(err, columns = ['alpha','error'])\n",
    "# lasso大概在0.2左右的时候，线性回归结果最大程度上得到了优化，比不加入lasso好一点的吧\n",
    "df_err[df_err.error == max(df_err.error)]\n",
    "\n",
    "# random forest \n",
    "# tree-based model对multi-collinearity不那么在意，所以我们不用太担心multi-collinearity多重共线性问题\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "np.mean(cross_val_score(rf,X_train,y_train,scoring = 'neg_mean_absolute_error', cv= 3))\n",
    "\n",
    "# tune models GridsearchCV \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'n_estimators':range(10,300,10), 'criterion':('mse','mae'), 'max_features':('auto','sqrt','log2')}\n",
    "\n",
    "gs = GridSearchCV(rf,parameters,scoring='neg_mean_absolute_error',cv=3)\n",
    "gs.fit(X_train,y_train)\n",
    "\n",
    "gs.best_score_\n",
    "gs.best_estimator_\n",
    "\n",
    "# test ensembles \n",
    "tpred_lm = lm.predict(X_test)\n",
    "tpred_lml = lm_l.predict(X_test)\n",
    "tpred_rf = gs.best_estimator_.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test,tpred_lm)\n",
    "mean_absolute_error(y_test,tpred_lml)\n",
    "mean_absolute_error(y_test,tpred_rf)\n",
    "\n",
    "mean_absolute_error(y_test,(tpred_lm+tpred_rf)/2)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
